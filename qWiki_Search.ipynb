{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qWiki_Search.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkl5oaA2YN0JTGTaTYFjkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jahnvi99/qWiki-Search/blob/main/qWiki_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBNsfkQALkuU",
        "outputId": "6ba067b1-9d4e-41ad-ba25-074d53a8440f"
      },
      "source": [
        "!pip install wikipedia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp37-none-any.whl size=11697 sha256=f51334dac18f80d2886df9b9b62a00e1416686c3d9fd898b24dec5d7ab8d902c\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-sy3im0Lt4r"
      },
      "source": [
        "#Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Jo3w3aLQMf",
        "outputId": "411866c8-a79b-4235-ba7e-b6b7b8d9eb23"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import wikipedia\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "nltk.download('punkt')\n",
        "import sklearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ofWFyg6LI8U2",
        "outputId": "51654cbb-879a-4795-c90d-6b89a329a549"
      },
      "source": [
        "sklearn.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.22.2.post1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK2vyRzCL_p4"
      },
      "source": [
        "#Finding relevant wikipedia pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJt4dH7kL-Ku",
        "outputId": "34dc6a87-5627-48a7-cc66-848240b6e702"
      },
      "source": [
        "query = input('Enter query: ')\n",
        "n = int(input('Enter number of sentences to be returned: '))\n",
        "\n",
        "titles = wikipedia.search(query, results=5)\n",
        "if not titles:\n",
        "\tprint ('The given query does not match any wikipedia page.')\n",
        "\texit()\n",
        "titles "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter query: Narendra Modi\n",
            "Enter number of sentences to be returned: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Narendra Modi',\n",
              " 'Narendra Modi Stadium',\n",
              " 'PM Narendra Modi',\n",
              " 'Premiership of Narendra Modi',\n",
              " 'List of international prime ministerial trips made by Narendra Modi']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVCUUKcrM5CT"
      },
      "source": [
        "#Extracting temporal sentences based only on year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzTSKRQXM35K"
      },
      "source": [
        "data = []\n",
        "for title in titles:\n",
        "    try:\n",
        "        raw_data = wikipedia.page(title).content.replace('\\n', ' ')\n",
        "        processed_data = re.sub('== References ==.+|== See Also ==.+', '', raw_data) #removing irrelevant data from content\n",
        "        data.append(processed_data)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "articles = [nltk.sent_tokenize(text) for text in data]\n",
        "temporal_sentences = []\n",
        "for article in articles:\n",
        "    for sentence in article:\n",
        "        if re.search(r'\\d{4}', sentence) is not None:               \n",
        "            temporal_sentences.append(re.sub('=+.+?=+', '', sentence)) #removing all headings and subheadings"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaJxLlDlNggA"
      },
      "source": [
        "#Creating the document word matrix A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zCOPQZp_YTv",
        "outputId": "54d45405-c86e-4961-e150-5bc66faff3ff"
      },
      "source": [
        "len(temporal_sentences)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reR86HN0NesB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd5dd47-2ef8-4e76-f5af-78afb60f34a9"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(temporal_sentences)\n",
        "tfidf.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(297, 2052)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYchZGQNv5z"
      },
      "source": [
        "#Creating the model to calculate A=WH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPZdTliBNuu3"
      },
      "source": [
        "nmf_model = NMF(n_components=1, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
        "W = nmf_model.transform(tfidf)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kcOKedHN3l6"
      },
      "source": [
        "#Selecting top documents based on the score from topic to document matrix(W)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iITTTkJBN3JE"
      },
      "source": [
        "top_sent_indices = np.argsort( W[:,0] )[::-1][0:n]\n",
        "best_sentences = [temporal_sentences[sent_index] for sent_index in top_sent_indices]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK_8J88iONEo"
      },
      "source": [
        "#Sort and print the final output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYwsC4zGLZH_",
        "outputId": "e67fd463-11a8-43ea-ab91-63d7f437adc7"
      },
      "source": [
        "  output = []\n",
        "for line in best_sentences:\n",
        "    year = re.search(r'\\d{4}', line).group()\n",
        "    output.append((year, line))\n",
        "sorted_output = sorted(output, key=lambda tup: tup[0], reverse = True)\n",
        "for item in sorted_output:\n",
        "\tprint(item)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('2018', '  On 13 October 2018, Modi was renamed as the BJP candidate for prime minister for the 2019 general election.')\n",
            "('2014', 'The following is a list of international prime ministerial trips made by Narendra Modi since he became the Prime Minister of India following the 2014 Indian general election.')\n",
            "('2014', '  After the Bharatiya Janata Party led National Democratic Alliance won a landslide in the 2014 Lok Sabha election, Narendra Modi was sworn in as the Prime Minister of India on 26 May 2014.')\n",
            "('2014', 'Narendra Modi was sworn in as the Prime Minister of India on 26 May 2014 at the Rashtrapati Bhavan.')\n",
            "('2013', \"     In September 2013 Modi was named the BJP's candidate for prime minister ahead of the 2014 Lok Sabha election.\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xg65aNpTN4I",
        "outputId": "80706492-b3c8-40e3-a843-2290e3d621d7"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import wikipedia\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def qwiki_search(query, n):\n",
        "  titles = wikipedia.search(query, results=5)\n",
        "  if not titles:\n",
        "    print ('The given query does not match any wikipedia page.')\n",
        "    exit()\n",
        "  data = []\n",
        "  for title in titles:\n",
        "      try:\n",
        "          raw_data = wikipedia.page(title).content.replace('\\n', ' ')\n",
        "          processed_data = re.sub('== References ==.+|== See Also ==.+', '', raw_data)#removing irrelevant data from content\n",
        "          data.append(processed_data)\n",
        "      except Exception:\n",
        "          pass\n",
        "\n",
        "  articles = [nltk.sent_tokenize(text) for text in data]\n",
        "  temporal_sentences = []\n",
        "  for article in articles:\n",
        "      for sentence in article:\n",
        "          if re.search(r'\\d{4}', sentence) is not None:               \n",
        "              temporal_sentences.append(re.sub('=+.+?=+', '', sentence))\n",
        "  tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf = tfidf_vectorizer.fit_transform(temporal_sentences)\n",
        "\n",
        " \n",
        "  nmf_model = NMF(n_components=1, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
        "\n",
        "  W = nmf_model.transform(tfidf)\n",
        "\n",
        " \n",
        "  top_sent_indices = np.argsort( W[:,0] )[::-1][0:n]\n",
        "  best_sentences = [temporal_sentences[sent_index] for sent_index in top_sent_indices]\n",
        "\n",
        " \n",
        "  output = []\n",
        "  for line in best_sentences:\n",
        "      year = re.search(r'\\d{4}', line).group()\n",
        "      output.append((year, line))\n",
        "  sorted_output = sorted(output, key=lambda tup: tup[0], reverse = True)\n",
        "  return sorted_output\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJV4QF_ZUv9u",
        "outputId": "051ad4d5-d2de-494f-fe57-1650e298fe8f"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  query = input('Enter query: ')\n",
        "  n = int(input('Enter number of sentences to be returned: '))\n",
        "  sentences = qwiki_search(query, n)\n",
        "  for item in sentences:\n",
        "    print(item)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter query: Google\n",
            "Enter number of sentences to be returned: 5\n",
            "('2017', 'In September 2017, the Google Search app on iOS was updated to feature the same functionality.')\n",
            "('2013', 'An Android app for My Maps, initially released in March 2013 under the name Google Maps Engine Lite, is also available.')\n",
            "('2012', 'In December 2012, the Google Maps application was separately made available in the App Store, after Apple removed it from its default installation of the mobile operating system version iOS 6 in September 2012.On January 29, 2013, Google Maps was updated to include a map of North Korea.')\n",
            "('2012', 'However, with the announcement of iOS 6 in June 2012, Apple announced that they had created their own Apple Maps mapping service, which officially replaced Google Maps when iOS 6 was released on September 19, 2012.')\n",
            "('2007', '  My Maps is a feature in Google Maps launched in April 2007 that enables users to create custom maps for personal use or sharing.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpLOtEs5VcVf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}